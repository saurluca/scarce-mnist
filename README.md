# scarce-fashion-mnist

In this Report we will explore a novel sparse MultiLayerPerceptron (MLP architecture), to solve MNIST. In is bsaed on the paper <...> and is inspired by the dendrite structure in the brain. 

## Models

- Base MLP 1 layer
- Base MLP multi layer
- Sparse Dendritic layer

## Factors

- SGD vs ADAM (2)
- fullbatch vs minibatch (just show once)
- Learning rate & epochs (soft)
- ReLU vs LeakyReLU vs Sigmoid (3)
- depth vs breath (number of parameters)

## TODOS

- [ ] Set up hyper paramter search based on factors
- [ ] Write report
- [ ] switch back to numpy after all the test have been made